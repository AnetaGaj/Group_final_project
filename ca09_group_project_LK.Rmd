---
title: "Final Group Project: AirBnB analytics"
date: "12 Oct 2021"
author: "Lindsey Zastawny, Lukas Kugler, Gautam Sreekumar, Aneta Gajdzinska, Danqing Huang, Shuyi Guo"
output:
  html_document:
    highlight: zenburn
    theme: flatly
    toc: yes
    toc_float: yes
    number_sections: yes
    code_folding: show
---

# Executive Summary:

> We analyzed how the prices for a four-night stay at an Airbnb in Munich depend on observable characteristics, such as its location.
We came up with the following 6 characteristics that best describe Airbnb prices in Munich:
i. Neighbourhood_Simplified - this shows in what area of the city the Airbnb is located. Certain areas, like the city centre, are especially pricy, given the popularity of these neighbourhoods among tourists.
ii. accommodates - this indicates how many individuals can stay at the Airbnb and is hence a proxy for its size. The larger the AirBnB, the costlier it is to stay there.
iii. room_type - indicates what kind of room is for rent. Entire apartments cost more than shared or private rooms.
iv. reviews_per_month -  this shows how many reviews Airbnb received last month. The more reviews, the lower the price of Airbnb on average. This effect likely occurs as cheaper AirBnB's are more frequented than pricy flats/rooms, hence cheaper AirBnB's receive more reviews monthly.
v. availability_30 - this shows how many days the AirBnB is available to rent in the coming 30 days. The more the availability, the higher the price. This is likely due to supply and demand: individuals are more easily able to afford cheap AirBnB's, hence more pricy accommodations often remain available.
vi. host_is_superhost - super hosts on Airbnb are experienced hosts with numerous past bookings. If an Airbnb host is a super host, this, on average, drives the accommodation prices down. This is likely because to qualify as a super host, one needs a large number of past bookings. It is more likely to receive more bookings if they are cheap. Hence on average, super hosts have cheaper accommodations.

```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```


```{r load-libraries, echo=FALSE}

library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(vroom)
```




In your final group assignment you have to analyse data about Airbnb listings and fit a model to predict the total cost for two people staying 4 nights in an AirBnB in a city. You can download AirBnB data from [insideairbnb.com](http://insideairbnb.com/get-the-data.html){target="_blank"}; it was originally scraped from airbnb.com. 

The following [Google sheet](https://docs.google.com/spreadsheets/d/1QrR-0PUGVWvDiVQL4LOk7w-xXwiDnM3dDtW6k15Hc7s/edit?usp=sharing) shows which cities you can use; please choose one of them and add your group name next to it, e.g., A7, B13. No city can have more than 2 groups per stream working on it; if this happens, I will allocate study groups to cities with the help of R's sampling.


All of the listings are a GZ file, namely they are archive files compressed by the standard GNU zip (gzip) compression algorithm. You can download, save and extract the file if you wanted, but `vroom::vroom()` or `readr::read_csv()` can immediately read and extract this kind of a file. You should prefer `vroom()` as it is faster, but if vroom() is limited by a firewall, please use `read_csv()` instead.


`vroom` will download the *.gz zipped file, unzip, and provide you with the dataframe. 


```{r load_data, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

# use cache=TRUE so you dont donwload the data everytime you knit

listings <- vroom("http://data.insideairbnb.com/germany/bv/munich/2021-09-28/data/listings.csv.gz") %>% 
       clean_names()

```


Even though there are many variables in the dataframe, here is a quick description of some of the variables collected, and you can find a [data dictionary here](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896)

- `price` = cost per night 
- `property_type`: type of accommodation (House, Apartment, etc.)
- `room_type`:

  - Entire home/apt (guests have entire place to themselves)
  - Private room (Guests have private room to sleep, all other rooms shared)
  - Shared room (Guests sleep in room shared with others)

- `number_of_reviews`: Total number of reviews for the listing
- `review_scores_rating`: Average review score (0 - 100)
- `longitude` , `latitude`: geographical coordinates to help us locate the listing
- `neighbourhood*`: three variables on a few major neighbourhoods in each city 


# Exploratory Data Analysis (EDA)

In the [R4DS Exploratory Data Analysis chapter](http://r4ds.had.co.nz/exploratory-data-analysis.html){target="_blank"}, the authors state:

> "Your goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation... EDA is fundamentally a creative process. And like most creative processes, the key to asking quality questions is to generate a large quantity of questions."


Conduct a thorough EDA. Recall that an EDA involves three things:

* Looking at the raw values.
    * `dplyr::glimpse()`
* Computing summary statistics of the variables of interest, or finding NAs
    * `mosaic::favstats()`
    * `skimr::skim()`
* Creating informative visualizations.
    * `ggplot2::ggplot()`
        * `geom_histogram()` or `geom_density()` for numeric continuous variables
        * `geom_bar()` or `geom_col()` for categorical variables
    * `GGally::ggpairs()` for scaterrlot/correlation matrix
        * Note that you can add transparency to points/density plots in the `aes` call, for example: `aes(colour = gender, alpha = 0.4)`
        
You may wish to have a level 1 header (`#`) for your EDA, then use level 2 sub-headers (`##`) to make sure you cover all three EDA bases. **At a minimum** you should address these questions:


- What are the correlations between variables? Does each scatterplot support a linear relationship between variables? Do any of the correlations appear to be conditional on the value of a categorical variable?
>According to the “model 7”, the correlation between cleanliness and value is the highest, which has 0.525 coefficient of correlation. From the scatterplot, we spot a linear correlation between the two variables.

At this stage, you may also find you want to use `filter`, `mutate`, `arrange`, `select`, or `count`. Let your questions lead you! 

## Observe Raw Values
``` {r, raw_values}
#observe data
dplyr::glimpse(listings)
```
## Create Summary Statistics

Through the skim, we observe that there are 74 variables and 4964 observations in the dataframe. There are 37 numeric variables and 9 logical variables. Once we change price to numreic variable in the next steps we will observe 38 numeric variables. 
```{r, summary_statistics}
#creating summary of our data 

mosaic::favstats(price ~ accommodates, data = listings)

skimr::skim(listings)

```

## Data wrangling

Notice that some of the price data (`price`) is given as a character string, e.g., "$176.00"

Since `price` is a quantitative variable, we need to make sure it is stored as numeric data `num` in the dataframe. To do so, we will first use `readr::parse_number()` which drops any non-numeric characters before or after the first number.

``` {r}
listings <- listings %>% 
  #make price a numeric variable
  mutate(price = parse_number(price))

#check that price is a numeric variable
typeof(listings$price)
```

Use `typeof(listing$price)` to confirm that `price` is now stored as a number.

``` {r, informative_visualization}
#create informative visualization about the data 
#histogram for reviews score
ggplot2::ggplot(data=listings,aes(x=review_scores_rating ))+
  geom_histogram()+
  labs(title = "Ratings")

#histogram for number of bedrooms
ggplot(listings,aes(x=bedrooms)) + 
  geom_histogram()

#histogram for price
ggplot(listings,aes(x=price)) + 
  geom_histogram()

#Scatterplot for the relation between price and number of beds
ggplot(listings, aes(x= beds, y =price))+
  geom_point()+
  geom_smooth(color="purple") + #add trendline
  theme_bw() +
  labs ( title = "Beds vs Price" )

#Scatterplot for the relation between ratings and their accuracy
ggplot(listings, aes(x= review_scores_rating, y = review_scores_accuracy ))+
  geom_point()+
  geom_smooth(color="green") + #add trendline
  theme_bw() +
  labs ( title = "Ratings vs Accuracy" )


#relation between review and certain reviews score
model7 <- lm(log(review_scores_rating) ~ review_scores_value + review_scores_cleanliness + review_scores_location, data=listings)
#view model summary
msummary(model7)
listings %>% select(review_scores_value, review_scores_cleanliness, review_scores_location) %>% 
GGally::ggpairs()
car::vif(model7)
```

> In all cases, please think about the message your plot is conveying. Don’t just say "This is my X-axis, this is my Y-axis", but rather what’s the **so what** of the plot. Tell some sort of story and speculate about the differences in the patterns in no more than a paragraph.

## Propery types


Next, we look at the variable `property_type`. We can use the `count` function to determine how many categories there are their frequency. What are the top 4 most common property types? What proportion of the total listings do they make up? 
>#Top 4 property types are: 
Entire rental unit	2453, equals to 49.4% of total listing		
Private room in rental unit	1334, equals to 26.9% of total listing				
Entire condominium (condo)	180, equal to 3.6% of total listing	
Private room in residential home	  152, equals to 3.1% of total listing



Since the vast majority of the observations in the data are one of the top four or five property types, we would like to create a simplified version of `property_type` variable that has 5 categories: the top four categories and `Other`. Fill in the code below to create `prop_type_simplified`.

``` {r, property_analysis}

#find out which property types are the top 5
count(listings, property_type) %>% 
  arrange(desc(n))

#create new simplified property type variable
listings <- listings %>%
  mutate(prop_type_simplified = case_when(
    property_type %in% c("Entire rental unit", #1 property type
                         "Private room in rental unit", #2 property type
                         "Entire condominium (condo)", #3 property type...
                         "Private room in residential home") ~ property_type, 
    TRUE ~ "Other"
  ))
  
#view new data
glimpse(listings)

```
Use the code below to check that `prop_type_simplified` was correctly made.

```{r, check_work}
#check that prop_type_simplified was made correctly
listings %>%
  count(property_type, prop_type_simplified) %>%
  arrange(desc(n))        
```        
It appears that the the simplified property type variable was correctly made. The top four property types each received their own category, while the rest of the property types are put into the "Other" category.


Airbnb is most commonly used for travel purposes, i.e., as an alternative to traditional hotels. We only want to include  listings in our regression analysis that are intended for travel purposes:

- What are the  most common values for the variable `minimum_nights`? 
The most common values for the variable `minimum_nights` are unsurprisingly one, two, and three nights. These would be the most common because many people may use Airbnb for a quick weekend getaway, and the owners who post on Airbnb probably realize this. The fourth most popular value for this variable was five nights, and these listings are probably going to be more attractive to those taking a weeklong vacation.

- Is there any value among the common values that stands out? 
None of the values in the top thre minimum nights stayed particularly stood out. The number of nights for the top three were simply between one and three night minimum stays, so even if you were looking for an Airbnb for a long weekend you would still qualify for these listings. The one value that kind of stood out to me was the 14 night minimum value. 14 nights is a bit too long for most vacations (for the average person or family), so it would only really appeal to someone looking for a longer-term stay (and at that point why not just make it a 21 or 30 night minimum?). 

- What is the likely intended purpose for Airbnb listings with this seemingly unusual value for `minimum_nights`?
The properties with slightly strange values for minimum_nights probably have varied reasons for such values. For example, for the really long minimum nights (100+ nights), the owner of the property may be targeting people who basically live in the city but for whatever reason may not be renting an actual apartment. Or, these properties may be targeting students who are studying abroad for the semester or year and are looking for accommodations. For other unusual values, the owner may have a certain schedule they like to follow when renting out the listing or possibly can only rent it for a certain period of time, so they create a very niche minimum number of nights to attract people who are looking for very specific properties to stay at.

Filter the airbnb data so that it only includes observations with `minimum_nights <= 4`

```{r}
#find most common values for minimum_nights
count(listings, minimum_nights) %>% 
  arrange(desc(n))

#filter data to only include obs with minimum nights less than or equal to 4
listings <- listings %>% 
  filter(minimum_nights <= 4)

glimpse(listings$minimum_nights)
```
        
# Mapping 

Visualisations of feature distributions and their relations are key to understanding a data set, and they can open up new lines of exploration. While we do not have time to go into all the wonderful geospatial visualisations one can do with R, you can use the following code to start with a map of your city, and overlay all AirBnB coordinates to get an overview of the spatial distribution of AirBnB rentals. For this visualisation we use the `leaflet` package, which includes a variety of tools for interactive maps, so you can easily zoom in-out, click on a point to get the actual AirBnB listing for that specific point, etc.

The following code, having downloaded a dataframe `listings` with all AirbnB listings in Milan, will plot on the map all AirBnBs where `minimum_nights` is less than equal to four (4). You could learn more about `leaflet`, by following [the relevant Datacamp course on mapping with leaflet](https://www.datacamp.com/courses/interactive-maps-with-leaflet-in-r)


```{r, out.width = '80%'}
#create mapping distribution of Munich Airbnb listings
leaflet(data = filter(listings, minimum_nights <= 4)) %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, #specify size of data points on map
                   fillColor = "blue", #specify color
                   fillOpacity = 0.4, #specify opacity of color
                   popup = ~listing_url,
                   label = ~property_type)
```

    
# Regression Analysis

For the target variable $Y$, we will use the cost for two people to stay at an Airbnb location for four (4) nights. 

Create a new variable called `price_4_nights` that uses `price`, and `accomodates` to calculate the total cost for two people to stay at the Airbnb property for 4 nights. This is the variable $Y$ we want to explain.
```{r}
#create new variable price_4_nights
listings <- listings %>% 
  #filter for listings that can accommodate 2 or more people
  filter(accommodates >= 2) %>% 
  #create price_4_nights variable
  mutate(price_4_nights = price*4) %>% 
    #filter out extreme outliers that skew outliers
  filter(price_4_nights < 20000)

```

Use histograms or density plots to examine the distributions of `price_4_nights` and `log(price_4_nights)`. Which variable should you use for the regression model? Why?

As seen in the graphs below, the log of `price_4_nights` should be used in the regression model. This is because the log provides a more normal-shaped bell curve, versus the regular distribution of price_4_nights which has a quite severe right skew (even after adjusting for some of the major outliers).

```{r}
#histogram price_4_nights
ggplot(listings, aes(x=price_4_nights)) + 
  geom_histogram()

#density plot for price_4_nights
ggplot(listings, aes(x=price_4_nights)) + 
  geom_density()

#histogram log(price_4_nights)
ggplot(listings, aes(x=price_4_nights)) + 
  geom_histogram() + 
  scale_x_log10()

#density plot log(price_4_nights)
ggplot(listings, aes(x=price_4_nights)) + 
  geom_density() + 
  scale_x_log10()


```

Fit a regression model called `model1` with the following explanatory variables: `prop_type_simplified`, `number_of_reviews`, and `review_scores_rating`. 

- Interpret the coefficient `review_scores_rating` in terms of `price_4_nights`.
> As the dependant variable is logged, the coefficient review_scores_rating thus shows by how many percent the price for four nights inreases, if the score rating increases by 1. As the coefficient is not statistically sifnificant, it can be determined that a change in score rating does not significantly change the price for 4 nights.

- Interpret the coefficient of `prop_type_simplified` in terms of `price_4_nights`.
> Compared to the reference group "Entire codominium (condo)", how much percent does price for four nights change if the property type changes to e.g. "Entire rental unit", i.e. compared to "Entire codominium (condo)", how much more or less (in %) are other property types.

We want to determine if `room_type` is a significant predictor of the cost for 4 nights, given everything else in the model. Fit a regression model called model2 that includes all of the explananatory variables in `model1` plus `room_type`. 

```{r, models}
#create model
model1 <- lm(log(price_4_nights) ~ prop_type_simplified + number_of_reviews + review_scores_rating, data=listings)
#view model summary
msummary(model1)
#graph model/correlations
listings %>%
  select(prop_type_simplified,number_of_reviews,review_scores_rating) %>% 
  ggpairs()
```

> In the first model, review_scores_rating was not significant. This is due to the number_of_reviews coliniarity with review_scores_rating. We now aim to determine which variable to include (by comparing the R^2 of the same model using the different variables:

```{r}
# create model with review_scores_rating
modelreview_scores_rating <- lm(log(price_4_nights) ~ prop_type_simplified + review_scores_rating, data=listings)
#view model summary
msummary(modelreview_scores_rating)

# create model with number_of_reviews
modelnumber_of_reviews <- lm(log(price_4_nights) ~ prop_type_simplified + number_of_reviews, data=listings)
#view model summary
msummary(modelnumber_of_reviews)
```

> As only review_scores_rating is significant, we will continue with this variable.

We want to determine if `room_type` is a significant predictor of the cost for 4 nights, given everything else in the model. Fit a regression model called model2 that includes all of the explanatory variables in `model1` plus `room_type`.

```{r}
#create model2
model2 <- lm(log(price_4_nights) ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type, data=listings)
#view model summary
msummary(model2)
#graph model/correlations
listings %>%
  select(prop_type_simplified,number_of_reviews,review_scores_rating,room_type) %>% 
  ggpairs()
```

> In the second model, room_type was not significant. This is could be due to a coliniarity with prop_type_simplified We now aim to determine which variable to include (by comparing the R^2 of the same model using the different variables:

```{r}
#create model with room_type
modelroom_type <- lm(log(price_4_nights) ~  number_of_reviews + review_scores_rating + room_type, data=listings)
#view model summary
msummary(modelroom_type)

#create model with prop_type_simplified
modelprop_type_simplified <- lm(log(price_4_nights) ~ prop_type_simplified + number_of_reviews + review_scores_rating, data=listings)
#view model summary
msummary(modelprop_type_simplified)
```

> the model with "room_type" has a slightly hifher R^2, hence we will use room_type for our following analyses

## Further variables/questions to explore on our own

> To understand what variables we want to include, we will first look at which variavles are correlated the most (+/-) with the price of four days

```{r}
ggcorr(listings)
```

> We can see that "accommodates" and "avalability_30" are highly correlated with the price for four days, thus we will include them in our analysis. Further, calculated_host_listing_count seems to hava a very positive impact on price per 4 days, thus we will explore this variavle too in our further analyses.

> So far we want to test for/ potentially include: "avalability_30", "accommodates", "calculated_host_listing_count", "room_type", "review_scores_rating"

Our dataset has many more variables, so here are some ideas on how you can extend your analysis

1. Are the number of `bathrooms`, `bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`? Or might these be co-linear variables?

> First, as `bathrooms`are na values only, we will mutate the text bathrooms into actual numbers in order to receive a measure for bathrooms

```{r}
listings <- listings %>% 
  mutate(bathrooms_text = parse_number(bathrooms_text)) # only keep number of bathrooms_text
typeof(listings$bathrooms_text) # test if bathrooms_text is now only numbers
```
> Second, we will check if `bathrooms`, `bedrooms`, `beds`, or size of the house (`accomodates`) they are co-linear variables.

```{r}
listings %>%
  select(bedrooms,accommodates,bathrooms_text) %>% 
  ggpairs()
```

> As all the variables are co-linear, we will only include one in our model. To choose which one, we will run regressions:

```{r}
#create model with bathrooms_text
modelbathrooms_text <- lm(log(price_4_nights) ~  room_type + review_scores_rating + bathrooms_text, data=listings)
#view model summary
msummary(modelbathrooms_text)

#create model with bedrooms
modelbedrooms <- lm(log(price_4_nights) ~  room_type + review_scores_rating + bedrooms, data=listings)
#view model summary
msummary(modelbedrooms)

#create model with beds
modelbeds <- lm(log(price_4_nights) ~  room_type + review_scores_rating + beds, data=listings)
#view model summary
msummary(modelbeds)

#create model with accommodates
modelaccommodates <- lm(log(price_4_nights) ~  room_type + review_scores_rating + accommodates, data=listings)
#view model summary
msummary(modelaccommodates)
```

> As R^2 is highest in the model that uses "accommodates", we will use this variable going forward

2. Do superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables?

```{r}
modelhost_is_superhost <- lm(log(price_4_nights) ~ room_type + review_scores_rating + host_is_superhost, data=listings)
#view model summary
msummary(modelhost_is_superhost)

modelhost_is_superhost2 <- lm(log(price_4_nights) ~host_is_superhost, data=listings)
#view model summary
msummary(modelhost_is_superhost2)
```

> Surprisingly, Superhosts charge statistically significantly lower prices compared to regular hosts
As shown trough the second regression, this is independant of our model.

3. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?

```{r}
modelinstant_bookable <- lm(log(price_4_nights) ~ room_type + review_scores_rating + instant_bookable, data=listings)
#view model summary
msummary(modelinstant_bookable)
```

> Our model shows that accomodations that are instant_bookable, have on average a 0.07% higher price for 4 nights. We thus want to include the variable potentially as well.

4. For all cities, there are 3 variables that relate to neighbourhoods: `neighbourhood`, `neighbourhood_cleansed`, and `neighbourhood_group_cleansed`. There are typically more than 20 neighbourhoods in each city, and it wouldn't make sense to include them all in your model. Use your city knowledge, or ask someone with city knowledge, and see whether you can group neighbourhoods together so the majority of listings falls in fewer (5-6 max) geographical areas. You would thus need to create a new categorical variabale `neighbourhood_simplified` and determine whether location is a predictor of `price_4_nights`

```{r}
# First, we choose which neighbourhood variable we will use
unique(listings["neighbourhood_cleansed"]) #this is the most granular, thus we will us it

unique(listings["neighbourhood"])

unique(listings["neighbourhood_group_cleansed"])

# Second, we will rename the neighbourhood to the more unified names "north","east","west","south","central" and name this new column "neighbourhood_simplified"

listings <- listings %>%
mutate(neighbourhood_simplified = ifelse(as.character(neighbourhood_cleansed) == "Hadern", "West", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Berg am Laim", "East", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Maxvorstadt", "West", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Sendling-Westpark", "South", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Neuhausen-Nymphenburg", "West", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Schwabing-West", "West", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Allach-Untermenzing", "North", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Au-Haidhausen", "South", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Schwanthalerhöhe", "West", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Ludwigsvorstadt-Isarvorstadt", "Central", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Feldmoching-Hasenbergl", "North", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Ramersdorf-Perlach", "East", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Thalkirchen-Obersendling-Forstenried-Fürstenried-Solln", "South", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Untergiesing-Harlaching", "South", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Schwabing-Freimann", "North", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Tudering-Riem", "East", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Bogenhausen", "East", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Sendling", "South", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Laim", "West", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Altstadt-Lehel", "Central", as.character(neighbourhood_cleansed))) %>% #rename to proper value
  mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Pasing-Obermenzing", "West", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Milbertshofen-Am Hart", "North", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Moosach", "West", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Obergiesing", "East", as.character(neighbourhood_cleansed))) %>% #rename to proper value
mutate(neighbourhood_cleansed = ifelse(as.character(neighbourhood_cleansed) == "Aubing-Lochhausen-Langwied", "West", as.character(neighbourhood_cleansed)))#rename to proper value
  
unique(listings["neighbourhood_simplified"])
```

```{r}
# Try model with neighbourhood_simplified
modelneighbourhood_simplified <- lm(log(price_4_nights) ~ room_type + review_scores_rating + neighbourhood_simplified, data=listings)
#view model summary
msummary(modelneighbourhood_simplified)
```
> The effects of neighbourhood_simplified are highly significant, hence we will use them in the final regression

5. What is the effect of `avalability_30` or `reviews_per_month` on `price_4_nights`, after we control for other variables?

> if avalability_30 the price for 4 days reduces 0.016% - this effect is also statitically significant
if reviews_per_month increase 1, then price per 4 nights decreases 0.02% - this effect is also statitically significant and likely caused as new listings are cheaper on the platform to receive reviews, hence more reviews per month/cheaper listings

```{r}
# Try model with avalability_30, reviews_per_month
modelavalability_30reviews_per_month <- lm(log(price_4_nights) ~ room_type + review_scores_rating + reviews_per_month + availability_30, data=listings)
#view model summary
msummary(modelavalability_30reviews_per_month)
```


## Diagnostics, collinearity, summary tables

> Models that we consider will contain all the variables that significantly impacted the price for 4 days in the previous tasks:
room_type, review_scores_rating, reviews_per_month, availability_30, neighbourhood_simplified, instant_bookable, host_is_superhost, accommodates, calculated_host_listing_count

```{r}
#As we already have identified which variables are potentially significant, lets first try a model with all variables
model_all <- lm(log(price_4_nights) ~ room_type + review_scores_rating + reviews_per_month + availability_30 + neighbourhood_simplified + instant_bookable + host_is_superhost + accommodates + calculated_host_listings_count, data=listings)
msummary(model_all)

#Most likely, price depends on where the property is and how many people it accommodates - thus we will use this as starting point and add variables from there to improve R^2
model_1 <- lm(log(price_4_nights) ~ accommodates + neighbourhood_simplified, data=listings)

#Add room_type
model_2 <- lm(log(price_4_nights) ~ accommodates + neighbourhood_simplified + room_type, data=listings)

#Add host_is_superhost
model_3 <- lm(log(price_4_nights) ~ accommodates + neighbourhood_simplified + room_type + host_is_superhost, data=listings)

#Add review_scores_rating
model_4 <- lm(log(price_4_nights) ~ accommodates + neighbourhood_simplified + room_type + host_is_superhost + review_scores_rating, data=listings)

#Add calculated_host_listings_count
model_5 <- lm(log(price_4_nights) ~ accommodates + neighbourhood_simplified + room_type + host_is_superhost + review_scores_rating + calculated_host_listings_count, data=listings)

#Add availability_30
model_6 <- lm(log(price_4_nights) ~ accommodates + neighbourhood_simplified + room_type + host_is_superhost + review_scores_rating + calculated_host_listings_count + availability_30, data=listings)

#Add instant_bookable
model_7 <- lm(log(price_4_nights) ~ accommodates + neighbourhood_simplified + room_type + host_is_superhost + review_scores_rating + calculated_host_listings_count + instant_bookable, data=listings)

#Asdd all variables
model_full <- lm(log(price_4_nights) ~ room_type + review_scores_rating + reviews_per_month + availability_30 + neighbourhood_simplified + instant_bookable + host_is_superhost + accommodates + calculated_host_listings_count, data=listings)
msummary(model_all)

#Remove all insignificant variables to arrive at the final model
model_f <- lm(log(price_4_nights) ~ room_type + reviews_per_month + availability_30 + neighbourhood_simplified + host_is_superhost + accommodates, data=listings)
msummary(model_f) #Look at summary table
car::vif(model_f) #Check for colinearity
autoplot(model_f) #Plot residuals
```

```{r}
# Create huxtable
huxreg(model_1, model_2, model_3, model_4, model_5, model_6, model_6, model_full, model_f, statistics = c("Adj. R Squared"="adj.r.squared",'Residual SE' = 'sigma')) #add the adjusted $R^2$, and the Residual Standard Error
```


As you keep building your models, it makes sense to:

1. Check the residuals, using `autoplot(model_x)`- done, pls see above
1. As you start building models with more explanatory variables, make sure you use `car::vif(model_x)`` to calculate the **Variance Inflation Factor (VIF)** for your predictors and determine whether you have colinear variables. A general guideline is that a VIF larger than 5 or 10 is large, and your model may suffer from colinearity. Remove the variable in question and run your model again without it. - done, pls see above

1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error. - done, pls see above

1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. - see below

```{r}
#create df with the data we need
listingsf <- listings %>%
mutate(mean_rating=(review_scores_cleanliness #create average rating column
+ review_scores_checkin
+ review_scores_location
+ review_scores_value
+ review_scores_rating
+ review_scores_accuracy
+ review_scores_communication)/7) %>%
filter(prop_type_simplified=="Private room in rental unit",number_of_reviews>=10,mean_rating>=4.5) #filter for the data we need

#"unlog" our model
model_ff <- lm(price_4_nights ~ room_type + reviews_per_month + availability_30 + neighbourhood_simplified + host_is_superhost + accommodates, data=listings)

#predict the price for 4 nights
predict.lm(model_ff, listingsf, interval = "prediction")
modelf_results <- broom::augment(model_ff, newdata=listingsf) #use final model - modelf with our newly created data frame

#Create summary table for CI
modelf_results2 <- modelf_results %>%
  summarize(predicted_mean=mean(.fitted,na.rm=T), #show predicted mean for 4 nights
        predicted_sd=sqrt(var(.fitted,na.rm=T)), #predict sde
        count_obs=n(), #show num. of observations
        t_critical=qt(0.975,count_obs-1), #set 95% interval for CI
        se_fitted=predicted_sd/sqrt(n()), #show t-critical of model
        errors=t_critical*se_fitted, #create erros to calculate bounds for CI
        CI_lower_bound = predicted_mean-errors, #create lower bound for CI
        CI_higher_bound = predicted_mean+errors) #create upper bound for CI

modelf_results2 #call the model
```

- By midnight on Monday 18 Oct 2021, you must upload on Canvas a short presentation (max 4-5 slides) with your findings, as some groups will be asked to present in class. You should present your Exploratory Data Analysis, as well as your best model. In addition, you must upload on Canvas your final report, written  using R Markdown to introduce, frame, and describe your story and findings. You should include the following in the memo:

1. Executive Summary: Based on your best model, indicate the factors that influence `price_4_nights`.
This should be written for an intelligent but non-technical audience. All
other sections can include technical writing.
> See summary at top

2. Data Exploration and Feature Selection: Present key elements of the data, including tables and
graphs that help the reader understand the important variables in the dataset. Describe how the
data was cleaned and prepared, including feature selection, transformations, interactions, and
other approaches you considered.


> First, to understand the kind of data we are dealing with, we employed the skim function to see how many variables are of the form: character (text), date, logical and numeric. After that, we changed the variable price from character to numeric since it better represents the accommodation price. Further, we wanted to explore ratings to understand the overall level of accommodations available in Munich. Subsequently, we created histograms to see how the number of bedrooms and prices look like. Whether smaller apartments with fewer bedrooms are more common in Munich or maybe bigger villas for bigger groups and how are they priced. Moreover, we explored the relationship between price and the number of beds. To understand how certain scores influence the overall review of the property, we analysed the values, cleanliness and locations score. 
Our analyses help users understand the pertinent variables in the dataset in the best way.

3. Model Selection and Validation: Describe the model fitting and validation process used. State
the model you selected and why they are preferable to other choices.


> We used two approaches to understand the potential variables for our model.
First, we plotted the correlations between the price for four nights and the other variables in the data frame. We then pre-selected highly correlated variables with price for further analysis.
Second, we used logic to identify what variables likely have the most impact on price, with characteristics like location and size of the AirBnB coming to mind.
After identifying potentially significant variables, we run multiple regression models mixing the variables in order to achieve i.) a high R^2, so a high explanation of the price using our variables, ii. Significant variables, so we only include variables that statistically significantly affect price, and iii. Achieve no colonesrity. All these goals are met with our final model, which compared to all other fits in the data has the highest R^2 (except for the model incl. all variables - but not all are significant in that model) and achieves the highest significance of variables and has no colinearity between variables.
The model we chose is modelf = lm(log(price_4_nights) ~ room_type + reviews_per_month + availability_30 + neighbourhood_simplified + host_is_superhost + accommodates, data=listings)

4. Findings and Recommendations: Interpret the results of the selected model and discuss
additional steps that might improve the analysis


> 1) No Multicollinearity: The independent variables are not collinear; this was verified through the VIF test, which resulted in VIFs of below 5 for all variables. Hence, this model satisfies the conditions necessary to build a regression model. 
2)Statistical Significance: All but one independent variable , room_type_hotelroom,  is statistically significant at the 5% level.The p value for the significant variables is less than 0.01.  
3)Adjusted R square is 39%, and therefore the model is somewhat of a good fit. We were able to obtain our best fit model by formulating multiple models and testing the significance of independent variables, before coming to a conclusion.
To improve the analysis, we could have employed advanced statistical methods such as backward or forward selection, which would have provided a more accurate model. Moreover, the data could have been cleaned more.

# Acknowledgements

- The data for this project is from [insideairbnb.com](insideairbnb.com)